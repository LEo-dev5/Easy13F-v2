import httpx
import asyncio
from lxml import html  # HTML íŒŒì‹±ìš© (pip install lxml í•„ìš”)
import logging

class SECClient:
    BASE_URL = "https://www.sec.gov/cgi-bin/browse-edgar"
    ARCHIVE_URL = "https://www.sec.gov/Archives"

    def __init__(self, user_email: str):
        self.headers = {
            "User-Agent": f"Easy13F-v2/1.0 ({user_email})",
            "Accept-Encoding": "gzip, deflate",
            "Host": "www.sec.gov"
        }
        self.client = httpx.AsyncClient(headers=self.headers, timeout=30.0, follow_redirects=True)

    async def close(self):
        await self.client.aclose()

    async def get_latest_filings_list(self, cik: str):
        """
        1. í•´ë‹¹ ê¸°ê´€ì˜ ìµœì‹  13F-HR ê³µì‹œ ëª©ë¡(Atom Feed)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        """
        params = {
            "action": "getcompany",
            "CIK": cik,
            "type": "13F-HR", 
            "dateb": "",
            "owner": "exclude",
            "count": 5, # ìµœì‹  5ê°œë§Œ í™•ì¸
            "output": "atom"
        }
        try:
            response = await self.client.get(self.BASE_URL, params=params)
            response.raise_for_status()
            return response.content # bytesë¡œ ë°˜í™˜ (lxml íŒŒì‹±ì„ ìœ„í•´)
        except Exception as e:
            print(f"âŒ [List Error] {cik}: {e}")
            return None

    async def get_information_table_xml(self, accession_number: str, cik: str):
            """
            [ìµœì¢… ìˆ˜ì • ë²„ì „] í…Œì´ë¸” êµ¬ì¡°ì— ì˜ì¡´í•˜ì§€ ì•Šê³ , í˜ì´ì§€ ë‚´ì˜ ëª¨ë“  XML ë§í¬ë¥¼ ì „ìˆ˜ ì¡°ì‚¬í•©ë‹ˆë‹¤.
            """
            acc_no_dash = accession_number.replace("-", "")
            cik_int = int(cik) # 0 ì œê±°
            index_url = f"{self.ARCHIVE_URL}/edgar/data/{cik_int}/{acc_no_dash}/{accession_number}-index.html"
            
            print(f"   ğŸ‘‰ Index Page ì ‘ì† ì‹œë„: {index_url}")

            try:
                resp = await self.client.get(index_url)
                tree = html.fromstring(resp.content)
                
                xml_href = None
                candidates = []

                # ì „ëµ: í˜ì´ì§€ì— ìˆëŠ” ëª¨ë“  <a> íƒœê·¸ ì¤‘ .xmlë¡œ ëë‚˜ëŠ” ê²ƒì„ ë‹¤ ê¸ì–´ëª¨ì€ë‹¤.
                all_links = tree.xpath('//a/@href')
                
                for href in all_links:
                    if not href.endswith(".xml"):
                        continue
                    
                    # ëŒ€ì†Œë¬¸ì í†µì¼
                    href_upper = href.upper()
                    
                    # [ì œì™¸ ì¡°ê±´] 
                    # 1. í‘œì§€(primary) ì œì™¸
                    if "PRIMARY" in href_upper:
                        continue
                    # 2. ìŠ¤íƒ€ì¼ì‹œíŠ¸(xsl) ì œì™¸ (í˜¹ì‹œ xmlë¡œ ëë‚ ê¹Œë´)
                    if "XSL" in href_upper:
                        continue
                    
                    candidates.append(href)

                # í›„ë³´êµ° ì¤‘ì—ì„œ 'infotable'ì´ë‚˜ 'information'ì´ ë“¤ì–´ê°„ ê±¸ ìµœìš°ì„ ìœ¼ë¡œ ì°¾ìŒ
                for cand in candidates:
                    if "INFOTABLE" in cand.upper() or "INFORMATION" in cand.upper():
                        xml_href = cand
                        break
                
                # ë§Œì•½ ëª…ì‹œì ì¸ ì´ë¦„ì´ ì—†ë‹¤ë©´, ë‚¨ì€ í›„ë³´ ì¤‘ ì²« ë²ˆì§¸ XMLì„ ì„ íƒ (ê°€ì¥ í° íŒŒì¼ì¼ í™•ë¥  ë†’ìŒ)
                if not xml_href and candidates:
                    xml_href = candidates[0]
                    print(f"   âš ï¸ ëª…ì‹œì ì¸ InfoTable ì´ë¦„ì„ ëª» ì°¾ì•„ì„œ, ì¶”ì •ë˜ëŠ” íŒŒì¼ì„ ì„ íƒí•¨: {xml_href}")

                if not xml_href:
                    print(f"   âŒ XML ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°œê²¬ëœ í›„ë³´: {candidates}")
                    return None

                print(f"   âœ… Target XML Found: {xml_href}")
                full_xml_url = f"https://www.sec.gov{xml_href}"
                xml_resp = await self.client.get(full_xml_url)
                return xml_resp.content

            except Exception as e:
                print(f"   âŒ [Download Error] {accession_number}: {e}")
                return None